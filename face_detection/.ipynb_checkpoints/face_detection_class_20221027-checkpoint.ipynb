{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c5f116d",
   "metadata": {},
   "source": [
    "## face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = './opencv_face_detector_uint8.pb'\n",
    "config = './opencv_face_detector.pbtxt'\n",
    "\n",
    "img = cv2.imread('./king_face.png')\n",
    "\n",
    "face_net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if face_net.empty() :\n",
    "    print('model load failed')\n",
    "    sys.exit()\n",
    "\n",
    "# blobFromImage(image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]])\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (300, 300), (104, 177, 123), swapRB = False)\n",
    "\n",
    "face_net.setInput(blob)\n",
    "out = face_net.forward()\n",
    "print(out.shape)\n",
    "detect = out[0, 0, :, :]\n",
    "print(detect.shape)  # (200,7) -> 7 : 0~1은 X, 2는 확률, 3 = x, 4 = y, 5 = w, 6 = h \n",
    "\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(200) :\n",
    "    confidence = detect[i, 2]  # 3번쨰에 확률이 있음\n",
    "\n",
    "    if confidence > 0.5 :\n",
    "        x1 = int(detect[i, 3] * w)\n",
    "        y1 = int(detect[i, 4] * h)\n",
    "        x2 = int(detect[i, 5] * w)\n",
    "        y2 = int(detect[i, 6] * h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 2)\n",
    "\n",
    "        text = 'Face : {}%'.format(round(confidence * 100, 2))\n",
    "        cv2.putText(img, text, (x1, y1-2), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.namedWindow('image', cv2.WINDOW_FULLSCREEN)\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c410b",
   "metadata": {},
   "source": [
    "## 응용 - webcam을 이용한 face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04546053",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = './opencv_face_detector_uint8.pb'\n",
    "config = './opencv_face_detector.pbtxt'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('camera open failed')\n",
    "    sys.exit()\n",
    "\n",
    "while True :\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret :\n",
    "        print('frame read failed')\n",
    "        break\n",
    "        \n",
    "    face_net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "    if face_net.empty() :\n",
    "        print('model load failed')\n",
    "        sys.exit()\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123), swapRB = False)\n",
    "\n",
    "    face_net.setInput(blob)\n",
    "    out = face_net.forward()\n",
    "    detect = out[0, 0, :, :]\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    for i in range(200) :\n",
    "        confidence = detect[i, 2]\n",
    "\n",
    "        if confidence > 0.5 :\n",
    "            x1 = int(detect[i, 3] * w)\n",
    "            y1 = int(detect[i, 4] * h)\n",
    "            x2 = int(detect[i, 5] * w)\n",
    "            y2 = int(detect[i, 6] * h)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,0,255), 2)\n",
    "\n",
    "            text = 'Face : {}%'.format(round(confidence * 100, 2))\n",
    "            cv2.putText(frame, text, (x1, y1-2), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.namedWindow('frame', cv2.WINDOW_FULLSCREEN)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(30) == 27 :\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c46138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = './res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "config = './deploy.prototxt'\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('model load failed')\n",
    "    sys.exit()\n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Go home')\n",
    "    sys.exit()\n",
    "    \n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret :\n",
    "        print('frame read failed')\n",
    "        break\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123), swapRB = False)\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    out = net.forward()\n",
    "    \n",
    "    detect = out[0, 0, :, :]\n",
    "    \n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    for i in range(200) :\n",
    "        confidence = detect[i, 2]\n",
    "        \n",
    "        if confidence > 0.5 :\n",
    "            x1 = int(detect[i, 3] * w)\n",
    "            y1 = int(detect[i, 4] * h)\n",
    "            x2 = int(detect[i, 5] * w)\n",
    "            y2 = int(detect[i, 6] * h)\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            \n",
    "            text = f'Face : {confidence * 100:.2f}%'\n",
    "            cv2.putText(frame, text, (x1, y1-2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 1, cv2.LINE_AA)\n",
    "            \n",
    "    cv2.imshow('image', frame)\n",
    "    \n",
    "    if cv2.waitKey(20) == 27 :\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb57152",
   "metadata": {},
   "source": [
    "## hand detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d83b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540efcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_style = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d27cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5) # false이면 동영상\n",
    "files = ['./both_hand.jpg']\n",
    "image = cv2.flip(cv2.imread(files[0]), 1) # 헷갈릴 수 있으므로 좌우를 뒤집어야 함\n",
    "image_bgr = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "annotated_image = image.copy()\n",
    "\n",
    "results = hands.process(image_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Handness', results.multi_handedness)\n",
    "print('Handness', results.multi_handedness[0].classification[0].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf251764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('landmark', results.multi_hand_world_landmarks[0].landmark)\n",
    "print('fingers :', results.multi_hand_world_landmarks[0].landmark[1])\n",
    "print('fingers :', results.multi_hand_world_landmarks[0].landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f803dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing.draw_landmarks(image = annotated_image, \n",
    "                         landmark_list=results.multi_hand_landmarks[1], connections=mp_hands.HAND_CONNECTIONS, \n",
    "                         landmark_drawing_spec=mp_drawing_style.get_default_hand_landmarks_style(), \n",
    "                         connection_drawing_spec=mp_drawing_style.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a31c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', annotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4d363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc1822c",
   "metadata": {},
   "source": [
    "## webcam을 통한 손가락 detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d592647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f34f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
